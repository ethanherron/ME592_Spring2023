{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3c82f9-6001-4f43-8e60-bb8d540dacc4",
   "metadata": {},
   "source": [
    "The following notebook is from the deep learning course at NYU taught by Dr. Chinmay Hedge. Here is the link to the repo https://github.com/chinmayhegde/dl-demos/blob/main/extra/visual_transformers.ipynb. The internal architecture code is based off of the lucidrains ViT implementations found here https://github.com/lucidrains/vit-pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef8d8b-1034-4ecf-b0b1-b17bc23bbec6",
   "metadata": {},
   "source": [
    "# Transformers in Computer Vision\n",
    "\n",
    "\n",
    "\n",
    "Transformer architectures owe their origins in natural language processing (NLP), and indeed form the core of the current state of the art models for most NLP applications.\n",
    "\n",
    "We will now see how to develop transformers for processing image data (and in fact, this line of deep learning research has been gaining a lot of attention in 2021). The *Vision Transformer* (ViT) introduced in [this paper](https://arxiv.org/pdf/2010.11929.pdf) shows how standard transformer architectures can perform very well on image. The high level idea is to extract patches from images, treat them as tokens, and pass them through a sequence of transformer blocks before throwing on a couple of dense classification layers at the very end.\n",
    "\n",
    "\n",
    "Some caveats to keep in mind: \n",
    "- ViT models are very cumbersome to train (since they involve a ton of parameters) so budget accordingly. \n",
    "- ViT models are a bit hard to interpret (even more so than regular convnets).\n",
    "- Finally, while in this notebook we will train a transformer from scratch, ViT models in practice are almost always *pre-trained* on some large dataset (such as ImageNet) before being transferred onto specific training datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0564aaab-654b-44d6-924b-7390fd622a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c66f59b-0cae-47ac-ac0c-09c37e24a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 196535509.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 166395183.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 131490824.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 33363447.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "DOWNLOAD_PATH = './data/mnist'\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 1000\n",
    "\n",
    "transform_mnist = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(DOWNLOAD_PATH, train=True, download=True,\n",
    "                                       transform=transform_mnist)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(DOWNLOAD_PATH, train=False, download=True,\n",
    "                                      transform=transform_mnist)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE_TEST, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e986e5-7d16-4b62-9a91-5e34c9426c8a",
   "metadata": {},
   "source": [
    "# The ViT Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will now set up the ViT model. There will be 3 parts to this model:\n",
    "\n",
    "* A ``patch embedding'' layer that takes an image and tokenizes it. There is some amount of tensor algebra involved here (since we have to slice and dice the input appropriately), and the `einops` package is helpful. We will also add learnable positional encodings as parameters.\n",
    "* A sequence of transformer blocks. This will be a smaller scale replica of the original proposed ViT, except that we will only use 4 blocks in our model (instead of 32 in the actual ViT).\n",
    "* A (dense) classification layer at the end.\n",
    "\n",
    "Further, each transformer block consists of the following components: \n",
    "\n",
    "* A *self-attention* layer with $H$ heads, \n",
    "* A one-hidden-layer (dense) network to collapse the various heads. For the hidden neurons, the original ViT used something called a [GeLU](https://arxiv.org/pdf/1606.08415.pdf) activation function, which is a smooth approximation to the ReLU. For our example, regular ReLUs seem to be working just fine. The original ViT also used Dropout but we won't need it here.\n",
    "* *layer normalization* preceeding each of the above operations.\n",
    "\n",
    "Some care needs to be taken in making sure the various dimensions of the tensors are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa5b878-27c8-4411-ab5e-eaab425bc3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.ReLU(), #nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce679970-1b89-4b96-bdff-d21e0e433e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(image_size=28, patch_size=7, num_classes=10, channels=1, dim=64, depth=4, heads=8, mlp_dim=128)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0c7cd23-1cde-4802-adc2-018ea397edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=7, p2=7)\n",
       "    (1): Linear(in_features=49, out_features=64, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (attend): Softmax(dim=-1)\n",
       "            (to_qkv): Linear(in_features=64, out_features=1536, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07167e6-872d-4edb-ab4b-cb8e6f2edc73",
   "metadata": {},
   "source": [
    "This is it -- 4 transformer blocks, followed by a linear classification layer. Let us quickly see how many trainable parameters are present in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcd77f04-4bf4-4e88-bfbd-0d8d98d24120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597002\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476560c6-1d20-44e0-b968-f2443b019575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, data_loader, loss_history, device):\n",
    "    total_samples = len(data_loader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_history.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ecd9563-0fa9-4fe9-920a-11ff2395e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_history, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct_samples += pred.eq(target).sum()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    loss_history.append(avg_loss)\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
    "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
    "          '{:5}'.format(total_samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f474ee1d-354b-4ab2-a716-d8ae51a531b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/60000 (  0%)]  Loss: 2.5202\n",
      "[10000/60000 ( 17%)]  Loss: 0.4539\n",
      "[20000/60000 ( 33%)]  Loss: 0.2913\n",
      "[30000/60000 ( 50%)]  Loss: 0.2001\n",
      "[40000/60000 ( 67%)]  Loss: 0.1900\n",
      "[50000/60000 ( 83%)]  Loss: 0.1432\n",
      "\n",
      "Average test loss: 0.1280  Accuracy: 9645/10000 (96.45%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/60000 (  0%)]  Loss: 0.0860\n",
      "[10000/60000 ( 17%)]  Loss: 0.1207\n",
      "[20000/60000 ( 33%)]  Loss: 0.1332\n",
      "[30000/60000 ( 50%)]  Loss: 0.1153\n",
      "[40000/60000 ( 67%)]  Loss: 0.0640\n",
      "[50000/60000 ( 83%)]  Loss: 0.1257\n",
      "\n",
      "Average test loss: 0.1156  Accuracy: 9643/10000 (96.43%)\n",
      "\n",
      "Epoch: 3\n",
      "[    0/60000 (  0%)]  Loss: 0.0875\n",
      "[10000/60000 ( 17%)]  Loss: 0.0775\n",
      "[20000/60000 ( 33%)]  Loss: 0.0281\n",
      "[30000/60000 ( 50%)]  Loss: 0.0609\n",
      "[40000/60000 ( 67%)]  Loss: 0.0602\n",
      "[50000/60000 ( 83%)]  Loss: 0.1314\n",
      "\n",
      "Average test loss: 0.0844  Accuracy: 9744/10000 (97.44%)\n",
      "\n",
      "Execution time: 53.68 seconds\n"
     ]
    }
   ],
   "source": [
    "# locate our GPU device and initialize it for training\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "N_EPOCHS = 3\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_loss_history, test_loss_history = [], []\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_epoch(model, optimizer, train_loader, train_loss_history, device)\n",
    "    evaluate(model, test_loader, test_loss_history, device)\n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df84b8-2d60-4886-9aad-e31fa1db35bd",
   "metadata": {},
   "source": [
    "## Patches\n",
    "\n",
    "\n",
    "\n",
    "Lets dig into the patching operation and try to gain some intuition on what the transformer is actually operating on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5be390cf-7aff-4b27-972c-7b686c60ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = test_set[0]\n",
    "image, class_ = sample\n",
    "print(image.shape)\n",
    "print(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "712cf34e-e4f8-48d9-9236-3b30d048b08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b027866-5cd8-4bf3-bb4c-442a5e683ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "image_size = image.shape[-1]\n",
    "patch_size = 7\n",
    "\n",
    "# patched_image = rearrange(image, 'h w -> (h w)') # flatten the image into a vector\n",
    "patched_image = rearrange(image.squeeze(), '(h p1) (w p2) -> (h w) p1 p2', p1=patch_size, p2=patch_size) # 'chop' flattened image into patches and reassemble\n",
    "print(patched_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c0731ce-3ca2-441f-9112-9764d3f26cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a 4x4 grid of images\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
    "\n",
    "# load the images and plot them\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # plot the sub-image\n",
    "        ax[i, j].imshow(patched_image[(i*4)+j].numpy())\n",
    "        ax[i, j].axis('off')\n",
    "\n",
    "# set the title of the figure\n",
    "fig.suptitle('16 Images', fontsize=16)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fc172ef-f288-46c0-a50b-3c0adc9410b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a 4x4 grid of images\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
    "\n",
    "# load the images and plot them\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # plot the sub-image\n",
    "        ax[i, j].hist(patched_image[(i*4)+j].numpy())\n",
    "\n",
    "# set the title of the figure\n",
    "fig.suptitle('Histogram of each patch', fontsize=16)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6faf0a7-cb09-4bbe-9984-112efe3a17fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me592",
   "language": "python",
   "name": "me592"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
